---
layout: template
menu : tutorial
title : Parallel jobs
---

              <h2 id="1">1. Introduction</h2>

              <p>Easy Batch was designed with data processing parallelism in mind. The core <code><em>Engine</em></code> implements the <code><em>java.util.concurrent.Callable</em></code> interface which turns it into a unit of work that can be submitted to a <code>java.util.concurrent.ExecutorService</code>.</p>
              <p>Using the <code><em>java.util.concurrent.ExecutorService</em></code> with a pool of threads allows you
                  to run multiple Easy Batch instances in parallel. There are at least 3 ways to process data in parallel:</p>
              <ol>
                  <li>Distributing input records to multiple batch engines</li>
                  <li>Splitting the data source into multiple parts which will be processed by separate engines</li>
                  <li>Filtering input records</li>
              </ol>

                <p>In this tutorial, you will see an example of implementing each of these techniques using Easy Batch.</p>

              <p>You will reuse the same application developed in the <a href="./helloworld.html">Hello world tutorial</a> but with a huge tweets data source:</p>

<div class="bs-callout bs-callout-code">
    <h5>tweets.csv</h5>
<pre><code>id,user,message
1,foo,easy batch rocks! #EasyBatch
2,bar,@foo I do confirm :-)
...
10000000,baz,@foo @bar what are you talking about? Am I in trouble?
</code></pre>
</div>

        <h2>2. Dispatching records</h2>

<p>In order to distribute work to multiple engines, Easy Batch provides the <code><em>RecordDispatcher</em></code> API:</p>

        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <p class="pull-center"><img class="ebi" src="../img/eb/dispatcher.jpg"/></p>
            </div>
        </div>

        <p>Easy Batch comes with two implementations of the <code><em>RecordDispatcher</em></code> API:</p>
<ul>
    <li><code><em>RoundRobinRecordDispatcher</em></code>: dispatches records to several <code><em>java.util.concurrent.BlockingQueue</em></code> queues in a round robin fashion</li>
    <li><code><em>ContentBasedRecordDispatcher</em></code>: dispatches records to several <code><em>java.util.concurrent.BlockingQueue</em></code> queues based on record content</li>
</ul>

<p>In this tutorial, you will learn how to use the <code><em>RoundRobinRecordDispatcher</em></code> to distribute tweets to 2 queues.</p>


<div class="bs-callout bs-callout-warning">
    <h5><i class="fa fa-info-circle"></i> Heads up!</h5>
    <p>Poison records serve as End-Of-Stream messages, they are used to "kill" the engine (graciously).</p>
    <p>Easy Batch provides the <code><em>PoisonRecord</em></code> utility class to stop the engine when all data has been read.
        Poison records have no business value, you should filter them using the convenient built-in <code><em>PoisonRecordFilter</em></code>.</p>
</div>

        <p>Here is the code to setup such a configuration:</p>

        <div class="bs-callout bs-callout-code">
<pre><code class="java">public class ParallelTutorialWithRecordDispatching {

    private static final int QUEUE_SIZE = 32;

    private static final int THREAD_POOL_SIZE = 2;

    public static void main(String[] args) throws Exception {

        // Input file tweets.csv
        File tweets = new File(args[0]);

        //Create queues
        BlockingQueue&lt;Record&gt; queue1 = new ArrayBlockingQueue&lt;Record&gt;(QUEUE_SIZE);
        BlockingQueue&lt;Record&gt; queue2 = new ArrayBlockingQueue&lt;Record&gt;(QUEUE_SIZE);

        // Build easy batch engines
        Engine engine1 = buildBatchEngine(queue1);
        Engine engine2 = buildBatchEngine(queue2);

        //create a 2 threads pool to call engines in parallel
        ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE);

        //submit workers to executor service
        Future&lt;Report&gt; reportFuture1 = executorService.submit(engine1);
        Future&lt;Report&gt; reportFuture2 = executorService.submit(engine2);

        <strong>//create a record dispatcher to dispatch records to previously created queues
        RecordDispatcher recordDispatcher
                    = new RoundRobinRecordDispatcher(Arrays.asList(queue1, queue2));

        //read data source and dispatch records to queues in round-robin fashion
        FlatFileRecordReader flatFileRecordReader = new FlatFileRecordReader(tweets);
        flatFileRecordReader.open();
        while (flatFileRecordReader.hasNextRecord()) {
            Record record = flatFileRecordReader.readNextRecord();
            recordDispatcher.dispatchRecord(record);
        }
        flatFileRecordReader.close();

        //send poison records when all input data has been dispatched to workers
        recordDispatcher.dispatchRecord(new PoisonRecord());</strong>

        //wait for easy batch instances termination and get partial reports
        Report report1 = reportFuture1.get();
        Report report2 = reportFuture2.get();

        <strong>//merge partial reports into a global one
        ReportMerger reportMerger = new DefaultReportMerger();
        Report finalReport = reportMerger.mergerReports(report1, report2);
        System.out.println(finalReport);</strong>

        //shutdown executor service
        executorService.shutdown();
    }

    public static Engine buildBatchEngine(BlockingQueue&lt;Record&gt; queue) {
        return new EngineBuilder()
            .reader(new QueueRecordReader(queue))
            .filter(new PoisonRecordFilter())
            .processor(new TweetProcessor())
            .build();
    }
}</code></pre>
        </div>

        <p>Since the <code><em>RecordDispatcher</em></code> dispatches records to a <code><em>java.util.concurrent.BlockingQueue</em></code>,
        you should be able to read data from this type of queues. Easy Batch comes with a built-in <code><em>QueueRecordReader</em></code> to
        save you from writing the reading code yourself.</p>

        <p>When the reader finishes reading the data source, it sends a <code><em>PoisonRecord</em></code> to stop engines.</p>

        <p>You have distributed the work across multiple engines, so you will get partial reports at the end of execution of each worker engine.
        How do you get a single global report for all the work? This is where the <code><em>ReportMerger</em></code> comes to play,
            that is, to merge partial reports into a global one.</p>

        <h2>3. Splitting the data source</h2>

        <p>It is a common technique to split the data source into multiple slices as follow:</p>

<div class="row">
    <div class="col-md-10 col-md-offset-1">
        <p class="pull-center"><img class="ebi" src="../img/eb/split.jpg"/></p>
    </div>
</div>

        <p>Easy Batch does not provide a feature to partition input data. If you decided to split your data source into multiples parts,
        you can still use Easy Batch to process them in parallel using a <code><em>java.util.concurrent.ExecutorService</em></code>.
            This would not have been possible if Easy Batch's engine wouldn't implement the <code><em>java.util.concurrent.Callable</em></code> interface.</p>

              <p>Here is a sample of how to use multiple engines to process data source parts in parallel:</p>

        <div class="bs-callout bs-callout-code">
<pre><code class="java">public class ParallelTutorialWithDataSplitting {

    private static final int THREAD_POOL_SIZE = 2;

    public static void main(String[] args) throws Exception {

        // Input file tweets-part1.csv
        File tweetsPart1 = new File(args[0]);

        // Input file tweets-part2.csv
        File tweetsPart2 = new File(args[1]);

        // Build worker engines
        Engine engine1 = buildEngine(tweetsPart1);
        Engine engine2 = buildEngine(tweetsPart2);

        //create a 2 threads pool to call worker engines in parallel
        ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE);

        Future&lt;Report&gt; report1 = executorService.submit(engine1);
        Future&lt;Report&gt; report2 = executorService.submit(engine2);

        System.out.println("Report 1 = " + report1.get());
        System.out.println("Report 2 = " + report2.get());

        executorService.shutdown();
    }

    private static Engine buildEngine(File file) throws Exception{
        return new EngineBuilder()
            .reader(new FlatFileRecordReader(file))
            .processor(new TweetProcessor())
            .build();
    }
}</code></pre>
        </div>

<div class="bs-callout bs-callout-warning">
    <h5><i class="fa fa-info-circle"></i> Heads up!</h5>
    <p>In this example, you have used multiple threads within the same JVM to process data in parallel. You can also launch separate JVMs for each part.</p>
    <p>The second point to pay attention to, you should consider as in this sample creating two engines with separate instances of record readers and processors
        to avoid any thread-safety issues.</p>
</div>

<h2>3. Filtering the data source</h2>

        <p>Sometimes it is just impossible to split the data source into multiple parts. The third technique is to use a single data source
        but to instruct worker engines to process separate parts and filter the rest of the data source.</p>

        <p>Let's see an example:</p>

<div class="row">
    <div class="col-md-10 col-md-offset-1">
        <p class="pull-center"><img class="ebi" src="../img/eb/filter.jpg"/></p>
    </div>
</div>

              <ul>
                  <li>The first engine instance will read data from <code>tweets.csv</code> file, process records 1-2 and filter records 3-4.</li>
                  <li>The second engine instance will also read data from <code>tweets.csv</code> file, process records 3-4 and filter records 1-2.</li>
              </ul>

              <p>The following listing shows the code to achieve this configuration:</p>

        <div class="bs-callout bs-callout-code">
<pre><code class="java">public class ParallelTutorialWithDataFiltering {

    private static final int THREAD_POOL_SIZE = 2;

    public static void main(String[] args) throws Exception {

        // Input file tweets.csv
        File tweets = new File(args[0]);

        <strong>// worker engine 1: process data from tweets.csv, filter records 3-4
        Engine engine1 = buildEngine(tweets, new RecordNumberGreaterThanFilter(2));

        // worker engine 2: process data from tweets.csv, filter records 1-2
        Engine engine2 = buildEngine(tweets, new RecordNumberLowerThanFilter(3));</strong>

        //create a 2 threads pool to call worker engines in parallel
        ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE);

        Future&lt;Report&gt; report1 = executorService.submit(engine1);
        Future&lt;Report&gt; report2 = executorService.submit(engine2);

        System.out.println("Report 1 = " + report1.get());
        System.out.println("Report 2 = " + report2.get());

        executorService.shutdown();
    }

    private static Engine buildEngine(File file, RecordFilter recordFilter) throws Exception{
        return new EngineBuilder()
            .reader(new FlatFileRecordReader(file))
            .filter(recordFilter)
            .processor(new TweetProcessor())
            .build();
    }
}</code></pre>
        </div>

              <h2>4. Running the tutorial</h2>

<p>To run the tutorials, proceed as follow:</p>
<div class="bs-callout bs-callout-code">
<pre><code>$>git clone https://github.com/benas/easy-batch.git
$>cd easy-batch
$>mvn install
$>cd easybatch-tutorials
$> # Launch the record dispatching tutorial
$>mvn exec:java -PrunParallelTutorialWithRecordDispatching
$> # Launch the data source splitting tutorial
$>mvn exec:java -PrunParallelTutorialWithDataSplitting
$> # Launch the data source filtering tutorial
$>mvn exec:java -PrunParallelTutorialWithDataFiltering
</code></pre>
</div>

<p>The complete source code of this tutorial is available <a href="https://github.com/benas/easy-batch/tree/master/easybatch-tutorials/src/main/java/org/easybatch/tutorials/advanced/parallel" target="_blank">here</a>.

<h2>4. Summary</h2>

              <p>In this tutorial, you have seen at least 3 ways of how to process data in parallel using multiple worker engines
                  in order to speed up the overall processing time.</p>
              <p>The following table summarizes the advantages and drawbacks for each approach:</p>
              <table class="table table-bordered table-condensed ">
                  <thead>
                  <tr class="alert-info">
                      <th>Approach</th>
                      <th>Advantages</th>
                      <th>Drawbacks</th>
                  </tr>
                  </thead>
                  <tbody>
                  <tr>
                      <td>Dispatching records</td>
                      <td><span class="text-success">Best way to distribute work across multiple worker engines.</span></td>
                      <td><span class="text-danger">Need to setup an additional record reader and queues.</span></td>
                  </tr>
                  <tr>
                      <td>Splitting the data source</td>
                      <td><span class="text-success">Each engine reads only its own part and not the whole data source</span></td>
                      <td><span class="text-danger">Need to split the data source into multiple parts</span></td>
                  </tr>
                  <tr>
                      <td>Filtering the data source</td>
                      <td><span class="text-success">No need to split the input data source into multiple parts</span></td>
                      <td><span class="text-danger">Each engine will read the whole data source</span></td>
                  </tr>
                  </tbody>
              </table>

        <p>Using the <code><em>RecordDispatcher</em></code> API should be your first choice when dealing with data processing in parallel
            because it is more efficient than other techniques and provides the most natural way of distributing the work across multiple engines.</p>

<h2>9. What's next?</h2>

<p>In the next, you will learn how to process data asynchronously using a JMS queue.</p>

<nav>
    <ul class="pager">
        <li class="previous"><a href="./spring.html"><span aria-hidden="true">&larr;</span> Spring tutorial</a></li>
        <li class="next"><a href="./jms.html">Asynchronous jobs tutorial<span aria-hidden="true">&rarr;</span></a></li>
    </ul>
</nav>

